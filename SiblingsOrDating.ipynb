{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Are They Siblings or Dating?\n",
        "## A Deep Learning Image Classification Project\n",
        "### By Andy Phan, Sanjay Karunamoorthy, Kevin Arleen"
      ],
      "metadata": {
        "id": "_yuDdYuxDBjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XkcwK3EUS6H",
        "outputId": "a2234465-7776-47b6-a655-b1ef4f7605e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "pip install praw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UbUH1U1PjlI",
        "outputId": "cf3c0604-6661-4249-fa15-8c2f0cca6ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import requests\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Uv0ALuxDVleF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit = praw.Reddit(\n",
        "#     client_id=\"SZ6ae6M47WrdQ37nACw10Q\",\n",
        "#     client_secret=\"XqzJnY1D3g2_uy1Mlu-Su65lsa2fAg\",\n",
        "#     user_agent=\"SiblingsOrDatingScraper\"\n",
        "# )"
      ],
      "metadata": {
        "id": "MK69kZJ2WoSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(reddit.read_only)"
      ],
      "metadata": {
        "id": "8tv8YSr0XCNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subreddit = reddit.subreddit(\"siblingsordating\")\n",
        "# for submission in subreddit.hot(limit=10):\n",
        "#     print(submission.title)"
      ],
      "metadata": {
        "id": "GKPrbMRKXCfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_dir = \"images\"\n",
        "# os.makedirs(os.path.join(base_dir, \"siblings\"), exist_ok=True)\n",
        "# os.makedirs(os.path.join(base_dir, \"dating\"), exist_ok=True)\n",
        "\n",
        "# for i, post in enumerate(subreddit.top(limit=1000)):\n",
        "#     if post.url.endswith(('.jpg', '.png', '.jpeg', '.webp')):\n",
        "#         post.comments.replace_more(limit=0)\n",
        "#         author_label = None\n",
        "\n",
        "#         def extract_label(text):\n",
        "#             text = text.lower()\n",
        "#             if 'sib' in text and 'dating' not in text:\n",
        "#                 return 'siblings'\n",
        "#             elif ('dating' in text or 'couple' in text) and 'sib' not in text:\n",
        "#                 return 'dating'\n",
        "#             return None\n",
        "\n",
        "#         # Step 1: Check top-level comments from the author\n",
        "#         for comment in post.comments:\n",
        "#             if comment.author and post.author and comment.author.name == post.author.name:\n",
        "#                 author_label = extract_label(comment.body)\n",
        "#                 if author_label:\n",
        "#                     break\n",
        "\n",
        "#         # Step 2: Check replies to others if no label found yet\n",
        "#         if not author_label:\n",
        "#             for comment in post.comments:\n",
        "#                 for reply in comment.replies:\n",
        "#                     if reply.author and post.author and reply.author.name == post.author.name:\n",
        "#                         author_label = extract_label(reply.body)\n",
        "#                         if author_label:\n",
        "#                             break\n",
        "#                 if author_label:\n",
        "#                     break\n",
        "\n",
        "#         # Save image to correct subfolder\n",
        "#         if author_label:\n",
        "#             try:\n",
        "#                 label_dir = os.path.join(base_dir, author_label)\n",
        "#                 filename = os.path.join(label_dir, f\"{i}.jpg\")\n",
        "#                 image_data = requests.get(post.url).content\n",
        "#                 with open(filename, 'wb') as f:\n",
        "#                     f.write(image_data)\n",
        "#                 print(f\"Saved: {filename} | Label: {author_label}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Failed to download image: {e}\")\n",
        "#         else:\n",
        "#             print(f\"Skipped post {i}: No author label found\")"
      ],
      "metadata": {
        "id": "SAMzPbjUXOg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/images\"\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# uploaded = files.upload()\n",
        "with zipfile.ZipFile(\"images.zip\", \"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"images\")\n",
        "# empty_files = []\n",
        "\n",
        "# for root, _, files in os.walk(data_dir):\n",
        "#     for file in files:\n",
        "#         path = os.path.join(root, file)\n",
        "#         if os.path.getsize(path) == 0:\n",
        "#             empty_files.append(path)\n",
        "\n",
        "# if empty_files:\n",
        "#     print(\"Empty image files found:\")\n",
        "#     for path in empty_files:\n",
        "#         print(path)\n",
        "# else:\n",
        "#     print(\"No empty files found.\")\n",
        "# for path in empty_files:\n",
        "#     os.remove(path)\n",
        "#     print(f\"Deleted: {path}\")"
      ],
      "metadata": {
        "id": "4Ly6Ps76CqVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "# removed = 0\n",
        "\n",
        "# for root, _, files in os.walk(\"images\"):\n",
        "#     for file in files:\n",
        "#         path = os.path.join(root, file)\n",
        "#         ext = os.path.splitext(file)[1].lower()\n",
        "#         if ext not in valid_exts or os.path.getsize(path) == 0:\n",
        "#             os.remove(path)\n",
        "#             print(f\"Deleted: {path}\")\n",
        "#             removed += 1\n",
        "\n",
        "# print(f\"Cleanup complete. Removed {removed} invalid or empty files.\")"
      ],
      "metadata": {
        "id": "V8IiB6lm2w1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "\n",
        "# for root, _, files in os.walk(\"images\"):\n",
        "#     for file in files:\n",
        "#         if file.endswith(\".webp\"):\n",
        "#             path = os.path.join(root, file)\n",
        "#             try:\n",
        "#                 img = Image.open(path).convert(\"RGB\")\n",
        "#                 new_path = path.replace(\".webp\", \".jpg\")\n",
        "#                 img.save(new_path, \"JPEG\")\n",
        "#                 os.remove(path)\n",
        "#                 print(f\"Converted: {file} → .jpg\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Failed to convert {file}: {e}\")"
      ],
      "metadata": {
        "id": "h7a6w4Ij24kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_files = []\n",
        "\n",
        "for root, _, files in os.walk(\"images\"):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        try:\n",
        "            img = tf.io.read_file(filepath)\n",
        "            img = tf.image.decode_image(img, channels=3)\n",
        "        except Exception as e:\n",
        "            print(f\"Corrupted or unreadable file: {filepath} | Error: {e}\")\n",
        "            bad_files.append(filepath)\n",
        "\n",
        "print(f\"\\nFound {len(bad_files)} bad files.\")\n",
        "\n",
        "for path in bad_files:\n",
        "    os.remove(path)\n",
        "    print(f\"Deleted: {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWvLL7_w3PV_",
        "outputId": "6b0699f4-9330-4819-9582-a8b0cfb64d5b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 0 bad files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# from google.colab import files\n",
        "\n",
        "# shutil.make_archive(\"images\", \"zip\", \"images\")\n",
        "# files.download(\"images.zip\")"
      ],
      "metadata": {
        "id": "CCdF0lzN1NOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 42,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 42,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "d4tQ2StzYoBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac37fd8-976a-4ab9-a4bb-f9f8d68fd068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 192 files belonging to 2 classes.\n",
            "Using 154 files for training.\n",
            "Found 192 files belonging to 2 classes.\n",
            "Using 38 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "rescale_layer = Rescaling(1/.255)\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "def preprocess_images(images, labels):\n",
        "    images = rescale_layer(images)\n",
        "    images = data_augmentation(images)\n",
        "    return images, labels\n",
        "\n",
        "train_ds = train_ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# For validation, just rescale (no augmentation):\n",
        "validation_ds = validation_ds.map(lambda x, y: (rescale_layer(x), y),\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "validation_ds = validation_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5A55_PVbC1Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_ds)"
      ],
      "metadata": {
        "id": "HjNNLwXW1PiL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fdfd76d9-6045-4b9d-974b-588651c4d6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 31);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Siblings', 'Dating']\n",
        "\n",
        "n_rows = 8\n",
        "n_cols = 4\n",
        "plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(n_rows*n_cols):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[labels[i]], fontsize=12)\n",
        "  plt.subplots_adjust(wspace=.2, hspace=.2)"
      ],
      "metadata": {
        "id": "4ZdkY_BjlFOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras import layers, models\n",
        "\n",
        "# model = keras.models.Sequential([\n",
        "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "#     layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "#     layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "#     layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(256, activation='relu'),\n",
        "#     layers.Dropout(0.5),\n",
        "#     layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "lKxyTte63JV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    \"best_model.keras\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"auto\"\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=1\n",
        "    )\n",
        "\n",
        "y_train = np.concatenate([y.numpy() for _, y in train_ds], axis=0)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3),\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint_cb],\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "# myEpochs = 30\n",
        "# myOptimizer = Adam(learning_rate=0.0001)\n",
        "# myLoss = 'binary_crossentropy'\n",
        "# myMetrics = ['accuracy']\n",
        "# model.compile(\n",
        "#     loss=myLoss,\n",
        "#     optimizer=myOptimizer,\n",
        "#     metrics=myMetrics\n",
        "# )\n",
        "# history = model.fit(train_ds,\n",
        "#                     validation_data=validation_ds,\n",
        "#                     epochs=myEpochs,\n",
        "#                     callbacks=[early_stop, reduce_lr],\n",
        "#                     class_weight=class_weights_dict)"
      ],
      "metadata": {
        "id": "l8zdSyrt6Cth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781abb17-4aa6-4d4d-8aac-1b3ceea8d33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 794ms/step - accuracy: 0.5893 - loss: 1.0829 - val_accuracy: 0.7368 - val_loss: 0.5713 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.6071 - loss: 0.8172 - val_accuracy: 0.7368 - val_loss: 0.5772 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 317ms/step - accuracy: 0.6388 - loss: 0.8502 - val_accuracy: 0.7105 - val_loss: 0.5874 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.5244 - loss: 0.8337 - val_accuracy: 0.7632 - val_loss: 0.5978 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - accuracy: 0.5579 - loss: 0.8289 - val_accuracy: 0.6842 - val_loss: 0.6105 - learning_rate: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint_cb],\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "best_model = tf.keras.models.load_model(\"best_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ptmKTyPLeNe",
        "outputId": "7df705d3-01c2-4b3f-8d9c-610c67869202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 734ms/step - accuracy: 0.5345 - loss: 0.7342 - val_accuracy: 0.7105 - val_loss: 0.5755 - learning_rate: 1.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - accuracy: 0.5738 - loss: 0.7169 - val_accuracy: 0.7368 - val_loss: 0.5790 - learning_rate: 1.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step - accuracy: 0.5104 - loss: 0.7393 - val_accuracy: 0.7368 - val_loss: 0.5820 - learning_rate: 1.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - accuracy: 0.5680 - loss: 0.6899 - val_accuracy: 0.7105 - val_loss: 0.5843 - learning_rate: 1.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.5405 - loss: 0.7041\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 353ms/step - accuracy: 0.5446 - loss: 0.7027 - val_accuracy: 0.7105 - val_loss: 0.5863 - learning_rate: 1.0000e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - accuracy: 0.5967 - loss: 0.6841 - val_accuracy: 0.7105 - val_loss: 0.5876 - learning_rate: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate(validation_ds)\n",
        "# best_model.evaluate(validation_ds)"
      ],
      "metadata": {
        "id": "CEHa6TL27X5a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf images\n",
        "best_val_loss, best_val_acc = best_model.evaluate(validation_ds)\n",
        "print(\"Best saved model - val_loss:\", best_val_loss, \"val_accuracy:\", best_val_acc)"
      ],
      "metadata": {
        "id": "kgWzxpSb-FYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46fb12f-e2f2-4d0a-8180-1e05d8454265"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7692 - loss: 0.5930\n",
            "Best saved model - val_loss: 0.5977979898452759 val_accuracy: 0.7631579041481018\n"
          ]
        }
      ]
    }
  ]
}